"""This script is to generate the HH dataset for SFT.

The generated dataset will be saved in the folder `data` with the following
structure:
        data
        └── helpful-base
            ├── train.json
            └── test.json

The `train.json` and `test.json` are the training and testing dataset, of which
the format is as follows:
    [
        ...
        {
            "prompt": str, the prompt,
            "chosen": str, the chosen response,
            "rejected": str, the rejected response,
            "random": str, the chosen response to another prompt randmly
                      seleted from the dataset,
            "paraphrase": str, a paraphrase of the rejected response,
            "variant": str, a response generated by a different model,
            "nonresponse": str, a sentence that is not a response to the prompt
            # so far, the non-response is randomly generated by GPT2-medium
        }
        ...
    ]
"""
import random
import json
from pathlib import Path
from tqdm import trange
from typing import List, Dict

import datasets
import google.generativeai as genai
from openai import OpenAI
from preference_datasets import extract_anthropic_prompt


KEY_IDX = 0
KEY_LIST = None
MODEL = 'gpt-3.5-turbo-1106'


def get_original_helpful():
    print(f'Loading HH dataset (helpful-base split) from Huggingface...')
    dataset = datasets.load_dataset(
        'Anthropic/hh-rlhf', data_dir='helpful-base', cache_dir='./data'
    )
    print('done')
    return dataset


def get_api_base_url() -> str:
    """Get the base URL of the API.

    Returns:
        base_url: the base URL of the API.
    """
    base_url = None
    file_path = Path('api_base_url.txt')
    if file_path.exists():
        with open(file_path, 'r') as f:
            base_url = f.read().strip()
    else:
        base_url = 'https://api.openai.com'
    return base_url


def get_api_key() -> str:
    """Get the list of API keys.

    Returns:
        api_key_list: the list of API keys.
    """
    global KEY_IDX, KEY_LIST
    if KEY_LIST is None:
        with open('api_keys.txt', 'r') as f:
            KEY_LIST = [line.strip() for line in f.readlines()]
    api_key = KEY_LIST[KEY_IDX % len(KEY_LIST)]
    KEY_IDX += 1
    return api_key


def get_gpt_completion(prompt: str) -> str:
    """Get the GPT-3 completion of the prompt.

    Args:
        prompt: the prompt.

    Returns:
        completion: the GPT-3 completion of the prompt.
    """
    client = OpenAI(
        api_key=get_api_key(),
        base_url=get_api_base_url(),
    )
    completion = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "user", "content": prompt},
        ],
        temperature=0.0,
        n=1,
    )
    return completion.choices[0].message.content


def get_gemini_completion(prompt: str) -> str:
    """Get the Gemini completion of the prompt.

    Args:
        prompt: the prompt.

    Returns:
        completion: the Gemini completion of the prompt.
    """
    genai.configure(api_key=get_api_key())
    model = genai.GenerativeModel('gemini-pro')
    response = model.generate_content(prompt)
    return response.text


def get_paraphrase(rejected_response: str) -> str:
    """Get a paraphrase of the rejected response.

    Args:
        rejected_response: the rejected response.

    Returns:
        paraphrase: a paraphrase of the rejected response.
    """
    gpt_prompt = f'Paraphrase the following sentence within 50 words:\n"{rejected_response}"\nParaphrase:'
    return get_gpt_completion(gpt_prompt)


def get_variant_response(prompt: str) -> str:
    """Get a variant response to the prompt.

    Args:
        prompt: the prompt.

    Returns:
        response: a variant response generated by .
    """
    gpt_prompt = f'Complete the following conversation within 50 words:\n{prompt}'
    return get_gpt_completion(gpt_prompt)


def get_nonreponse(prompt: str) -> str:
    """Get a non-response to the prompt.

    Args:
        prompt: the prompt.

    Returns:
        nonresponse: a non-response.
    """
    gpt_prompt = f'Give me a random sentence.'
    return get_gpt_completion(gpt_prompt)


def convert_helpful_base(dataset: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """Convert the HH dataset to the format described above.

    Args:
        dataset: the original HH helpful-base subset.

    Returns:
        converted_dataset: the converted dataset.
    """
    converted_dataset = []
    for idx in trange(0, len(dataset) -1):
        ex = dataset[idx]
        prompt = extract_anthropic_prompt(ex['chosen'])
        chosen_response = ex['chosen'][len(prompt):]
        rejected_response = ex['rejected'][len(prompt):]
        variant_response = get_variant_response(prompt)
        non_response =  get_nonreponse(prompt)
        paraphrase = get_paraphrase(chosen_response)

        while True:
            random_idx = random.randint(0, len(dataset) - 1)
            if random_idx != idx:
                break
        random_prompt = extract_anthropic_prompt(dataset[random_idx]['chosen'])
        random_response = dataset[random_idx]['chosen'][len(random_prompt):]

        converted_dataset.append({
            'prompt': prompt,
            'chosen': chosen_response,
            'rejected': rejected_response,
            'random': random_response,
            'variant': variant_response,
            'paraphrase': paraphrase,
            'nonresponse': non_response
        })
    return converted_dataset


def main() -> None:
    helpful_dataset = get_original_helpful()
    print('Converting the test set...')
    converted_test = convert_helpful_base(helpful_dataset['test'])
    with open('data/helpful-base/test.json', 'w') as f:
        f.write(json.dumps(converted_test))
    print('done')
    print('converting the training set...')
    converted_train = convert_helpful_base(helpful_dataset['train'])
    with open('data/helpful-base/train.json', 'w') as f:
        f.write(json.dumps(converted_train))
    print('done')


if __name__ == '__main__':
    main()
